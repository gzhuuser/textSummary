{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "openai key:\n",
    "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  可用4\n",
    "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 3.5\n",
    "\n",
    "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"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "标题: 使用 # 来表示不同级别的标题，比如：\n",
    "\n",
    "# 一级标题\n",
    "## 二级标题\n",
    "### 三级标题\n",
    "粗体: 使用 ** 或 __ 来包围文本，例如：\n",
    "\n",
    "**这是粗体文本** 或 __这是粗体文本__\n",
    "斜体: 使用 * 或 _ 来包围文本，例如：\n",
    "\n",
    "*这是斜体文本* 或 _这是斜体文本_\n",
    "删除线: 使用 ~~ 来包围文本，例如：\n",
    "\n",
    "~~这是带有删除线的文本~~\n",
    "链接: 使用 []() 来创建一个链接，例如：\n",
    "\n",
    "[百度](http://www.baidu.com)\n",
    "图片: 使用 ![]() 来插入一个图片，例如：\n",
    "\n",
    "![图片描述](图片链接)\n",
    "无序列表: 使用 * 或 - 或 + 后接空格来创建无序列表，例如：\n",
    "\n",
    "* 项目1\n",
    "- 项目2\n",
    "+ 项目3\n",
    "有序列表: 使用数字和点后接空格来创建有序列表，例如：\n",
    "\n",
    "1. 项目1\n",
    "2. 项目2\n",
    "3. 项目3\n",
    "引用: 使用 > 来创建引用，例如：\n",
    "\n",
    "> 这是一段引用\n",
    "代码: 使用 ` ` 来插入内联代码，例如 这是一段代码。使用 ``` ``` 来插入代码块，"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HTTP_PROXY'] = \"127.0.0.1:10809\"\n",
    "os.environ['HTTPS_PROXY']=\"127.0.0.1:10809\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(model_name='gpt-3.5-turbo-16k', temperature=0, request_timeout=50)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 从key文件读取key值\n",
    "* 输入参数: file_path 文件路径\n",
    "* 返回值: 存有key的列表"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def read_keys_from_file(file_path):\n",
    "    key_pool = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            key = line.strip()  # 去掉每一行的换行符\n",
    "            key_pool.append(key)  # 将每一行存入key池中\n",
    "    return key_pool"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# 读取key\n",
    "file_path = \"key.txt\"  # 将这个替换为你的txt文件的路径\n",
    "key_pool = read_keys_from_file(file_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 读取PDF文档函数\n",
    "* 参数:文件路径file_path,提取前n页\n",
    "* 返回值:一个列表"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "\n",
    "def read_pdf(file_path, n):\n",
    "    inner = []\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "            # 提取前n页\n",
    "            for i, page in enumerate(pdf.pages):\n",
    "                # 如果已经处理了n页，就停止\n",
    "                if i == n:\n",
    "                    break\n",
    "                inner.append(page.extract_text())\n",
    "    return inner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 按页数进行划分\n",
    "* 参数:inner->一个装有每一页pdf的列表\n",
    "* 参数:group_size->每个组的大小\n",
    "* 返回值:一个列表\n",
    "\n",
    "> 分割逻辑:\n",
    "> 以 inner = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 举例\n",
    "第一次循环：i = 0，子列表为 inner[0:0+4] = [1, 2, 3, 4]\n",
    "第二次循环：i = 3，子列表为 inner[3:3+4] = [4, 5, 6, 7]\n",
    "第三次循环：i = 6，子列表为 inner[6:6+4] = [7, 8, 9, 10]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def group_inner(inner, group_size):\n",
    "    # 将inner按照每n页为一组进行分割\n",
    "    \"\"\"\n",
    "\n",
    "    :param inner:\n",
    "    :param group_size:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    grouped_inner = [inner[i:min(i + group_size, len(inner))] for i in range(0, len(inner), group_size - 1)]\n",
    "    return grouped_inner\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "content = read_pdf(r'./data/KT820说明书V2.0 201909.pdf', 15)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "inner = group_inner(content, 5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from langchain.prompts import  ChatPromptTemplate\n",
    "prompts = \"\"\"\n",
    "    ----\n",
    "    {text}\n",
    "    ----\n",
    "    帮我把上面内容总结成2-4个目录，目录不要子目录，目录为简洁摘要，其它内容不用给我\n",
    "    \"\"\"\n",
    "\n",
    "prompts2 = \"\"\"\n",
    "    abstract:\n",
    "    ----\n",
    "    {abstract}\n",
    "    ----\n",
    "    text:\n",
    "    ----\n",
    "    {text}\n",
    "    ----\n",
    "\n",
    "    跟据上面的摘要，找出下面内容中每个摘要对应的开始位置内容,如果涉及到目录部分,有一大串的...就只返回三个就行,不用返回全部.：\n",
    "    返回格式:\n",
    "    [{respond_struction}]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompts3 = \"\"\"\n",
    "    text1:\n",
    "    ----\n",
    "    {text1}\n",
    "    ----\n",
    "    text2:\n",
    "    ----\n",
    "    {text2}\n",
    "    ----\n",
    "\n",
    "        现在，你有两个字典格式的文本字符串，它们分别命名为 text1 和 text2。这两个字典中都有一个content字段，你需要判断这两个字段中的内容是否相似。\n",
    "        如果它们的content相似，那么你需要合并这两个文本中的content字段的内容，并基于这个新的content生成一个新的abstract。返回的数据格式应该为一个字典，如下所示：\n",
    "        返回格式:\n",
    "        [{respond_struction}]\n",
    "        如果它们的content不相似，那么直接返回原来的两个字典格式的字符串文本 text1 和 text2。\n",
    "\n",
    "\"\"\"\n",
    "promptsTemplate = ChatPromptTemplate.from_template(prompts)\n",
    "promptsTemplate2 = ChatPromptTemplate.from_template(prompts2)\n",
    "promptsTemplate3 = ChatPromptTemplate.from_template(prompts3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 指定返回值格式\n",
    "> 返回值格式采用json数据,包含三部分:关键词,开始词,结束词\n",
    "### langchain的json格式\n",
    "1. 先定义单个模式,Schema = ResponseSchema(name=\"\",description=\"\")\n",
    "2. 然后将多个模式组合在一起response_schemas = [abstract_schema, start_schema, end_schema]\n",
    "3. 通过结构输出解析函数解析成结构对象 = StructuredOutputParser(response_schemas = response_schemas)\n",
    "4. 最后将结构对象解析成json格式的内容\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "result_schema = ResponseSchema(name='result', description=\"这一部分是一个数组,用来记录返回的内容的,里面的每一项都是一个字典,每个字典里面有两个key,一个key名为abstract。其对应的内容是摘要部分的内容, 也就是用来记录摘要的。另一个key的名字是content,这一部分是返回和上面摘要部分相关的全部内容,有n个摘要就返回n个内容\")\n",
    "# abstract_schema = ResponseSchema(name=\"abstract\",description=\"这是摘要部分的内容, 也就是用来记录摘要的\")\n",
    "# content_schema = ResponseSchema(name=\"content\",description=\"返回和上面摘要部分相关的全部内容,有n个摘要就返回n个内容\")\n",
    "\n",
    "response_schemas = [result_schema]\n",
    "out_parse = StructuredOutputParser(response_schemas = response_schemas)\n",
    "format_instructions = out_parse.get_format_instructions()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 制作两条链来定位\n",
    "* 第一条链用来摘要总结文本内容,第一条链用3.5的模型\n",
    "* 第二条链用来根据摘要来定位文本内容,第二条链用3.5模型"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(llm=llm, prompt=promptsTemplate)\n",
    "# llm2 = ChatOpenAI(model_name='gpt-4-0613', temperature=0.2)\n",
    "chain2 = LLMChain(llm=llm, prompt=promptsTemplate2)\n",
    "chain3 = LLMChain(llm=llm, prompt=promptsTemplate3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目录：\n",
      "1. 产品简介\n",
      "2. 编程基础\n",
      "3. G功能\n",
      "4. MST代码\n",
      "5. 刀补C功能\n",
      "6. 宏程序\n",
      "7. 图形功能\n",
      "8. 操作方式和界面显示\n",
      "9. 安全操作\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 16.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: You exceeded your current quota, please check your plan and billing details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[17], line 13\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m text \u001B[38;5;129;01min\u001B[39;00m inner:\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     11\u001B[0m         \u001B[38;5;66;03m# os.environ[\"OPENAI_API_KEY\"] = key_pool[random.randint(0,len(key_pool)-1)]\u001B[39;00m\n\u001B[0;32m     12\u001B[0m         \u001B[38;5;66;03m# print(os.environ.get(\"OPENAI_API_KEY\"))\u001B[39;00m\n\u001B[1;32m---> 13\u001B[0m         response\u001B[38;5;241m=\u001B[39m\u001B[43mchain\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     14\u001B[0m         \u001B[38;5;28mprint\u001B[39m(response)\n\u001B[0;32m     15\u001B[0m         res \u001B[38;5;241m=\u001B[39m chain2\u001B[38;5;241m.\u001B[39mrun(text\u001B[38;5;241m=\u001B[39mtext,abstract\u001B[38;5;241m=\u001B[39mresponse,respond_struction\u001B[38;5;241m=\u001B[39mformat_instructions)\n",
      "File \u001B[1;32mE:\\software\\Anaconda3\\envs\\myenv\\lib\\site-packages\\langchain\\chains\\base.py:239\u001B[0m, in \u001B[0;36mChain.run\u001B[1;34m(self, callbacks, *args, **kwargs)\u001B[0m\n\u001B[0;32m    236\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m(args[\u001B[38;5;241m0\u001B[39m], callbacks\u001B[38;5;241m=\u001B[39mcallbacks)[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_keys[\u001B[38;5;241m0\u001B[39m]]\n\u001B[0;32m    238\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m args:\n\u001B[1;32m--> 239\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_keys[\u001B[38;5;241m0\u001B[39m]]\n\u001B[0;32m    241\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m kwargs \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m args:\n\u001B[0;32m    242\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    243\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`run` supported with either positional arguments or keyword arguments,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    244\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m but none were provided.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    245\u001B[0m     )\n",
      "File \u001B[1;32mE:\\software\\Anaconda3\\envs\\myenv\\lib\\site-packages\\langchain\\chains\\base.py:140\u001B[0m, in \u001B[0;36mChain.__call__\u001B[1;34m(self, inputs, return_only_outputs, callbacks)\u001B[0m\n\u001B[0;32m    138\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m, \u001B[38;5;167;01mException\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    139\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e)\n\u001B[1;32m--> 140\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[0;32m    141\u001B[0m run_manager\u001B[38;5;241m.\u001B[39mon_chain_end(outputs)\n\u001B[0;32m    142\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001B[1;32mE:\\software\\Anaconda3\\envs\\myenv\\lib\\site-packages\\langchain\\chains\\base.py:134\u001B[0m, in \u001B[0;36mChain.__call__\u001B[1;34m(self, inputs, return_only_outputs, callbacks)\u001B[0m\n\u001B[0;32m    128\u001B[0m run_manager \u001B[38;5;241m=\u001B[39m callback_manager\u001B[38;5;241m.\u001B[39mon_chain_start(\n\u001B[0;32m    129\u001B[0m     {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m},\n\u001B[0;32m    130\u001B[0m     inputs,\n\u001B[0;32m    131\u001B[0m )\n\u001B[0;32m    132\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    133\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m--> 134\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    135\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m new_arg_supported\n\u001B[0;32m    136\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(inputs)\n\u001B[0;32m    137\u001B[0m     )\n\u001B[0;32m    138\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m, \u001B[38;5;167;01mException\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    139\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e)\n",
      "File \u001B[1;32mE:\\software\\Anaconda3\\envs\\myenv\\lib\\site-packages\\langchain\\chains\\llm.py:69\u001B[0m, in \u001B[0;36mLLMChain._call\u001B[1;34m(self, inputs, run_manager)\u001B[0m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_call\u001B[39m(\n\u001B[0;32m     65\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m     66\u001B[0m     inputs: Dict[\u001B[38;5;28mstr\u001B[39m, Any],\n\u001B[0;32m     67\u001B[0m     run_manager: Optional[CallbackManagerForChainRun] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m     68\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Dict[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mstr\u001B[39m]:\n\u001B[1;32m---> 69\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     70\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcreate_outputs(response)[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32mE:\\software\\Anaconda3\\envs\\myenv\\lib\\site-packages\\langchain\\chains\\llm.py:79\u001B[0m, in \u001B[0;36mLLMChain.generate\u001B[1;34m(self, input_list, run_manager)\u001B[0m\n\u001B[0;32m     77\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Generate LLM result from inputs.\"\"\"\u001B[39;00m\n\u001B[0;32m     78\u001B[0m prompts, stop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprep_prompts(input_list, run_manager\u001B[38;5;241m=\u001B[39mrun_manager)\n\u001B[1;32m---> 79\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mllm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate_prompt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     80\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprompts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_child\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\n\u001B[0;32m     81\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\software\\Anaconda3\\envs\\myenv\\lib\\site-packages\\langchain\\chat_models\\base.py:143\u001B[0m, in \u001B[0;36mBaseChatModel.generate_prompt\u001B[1;34m(self, prompts, stop, callbacks)\u001B[0m\n\u001B[0;32m    136\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgenerate_prompt\u001B[39m(\n\u001B[0;32m    137\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    138\u001B[0m     prompts: List[PromptValue],\n\u001B[0;32m    139\u001B[0m     stop: Optional[List[\u001B[38;5;28mstr\u001B[39m]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    140\u001B[0m     callbacks: Callbacks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    141\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m LLMResult:\n\u001B[0;32m    142\u001B[0m     prompt_messages \u001B[38;5;241m=\u001B[39m [p\u001B[38;5;241m.\u001B[39mto_messages() \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m prompts]\n\u001B[1;32m--> 143\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt_messages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\software\\Anaconda3\\envs\\myenv\\lib\\site-packages\\langchain\\chat_models\\base.py:91\u001B[0m, in \u001B[0;36mBaseChatModel.generate\u001B[1;34m(self, messages, stop, callbacks)\u001B[0m\n\u001B[0;32m     89\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m, \u001B[38;5;167;01mException\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     90\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_llm_error(e)\n\u001B[1;32m---> 91\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[0;32m     92\u001B[0m llm_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_combine_llm_outputs([res\u001B[38;5;241m.\u001B[39mllm_output \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m results])\n\u001B[0;32m     93\u001B[0m generations \u001B[38;5;241m=\u001B[39m [res\u001B[38;5;241m.\u001B[39mgenerations \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m results]\n",
      "File \u001B[1;32mE:\\software\\Anaconda3\\envs\\myenv\\lib\\site-packages\\langchain\\chat_models\\base.py:83\u001B[0m, in \u001B[0;36mBaseChatModel.generate\u001B[1;34m(self, messages, stop, callbacks)\u001B[0m\n\u001B[0;32m     79\u001B[0m new_arg_supported \u001B[38;5;241m=\u001B[39m inspect\u001B[38;5;241m.\u001B[39msignature(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate)\u001B[38;5;241m.\u001B[39mparameters\u001B[38;5;241m.\u001B[39mget(\n\u001B[0;32m     80\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_manager\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     81\u001B[0m )\n\u001B[0;32m     82\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 83\u001B[0m     results \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     84\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate(m, stop\u001B[38;5;241m=\u001B[39mstop, run_manager\u001B[38;5;241m=\u001B[39mrun_manager)\n\u001B[0;32m     85\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m new_arg_supported\n\u001B[0;32m     86\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate(m, stop\u001B[38;5;241m=\u001B[39mstop)\n\u001B[0;32m     87\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m m \u001B[38;5;129;01min\u001B[39;00m messages\n\u001B[0;32m     88\u001B[0m     ]\n\u001B[0;32m     89\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m, \u001B[38;5;167;01mException\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     90\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_llm_error(e)\n",
      "File \u001B[1;32mE:\\software\\Anaconda3\\envs\\myenv\\lib\\site-packages\\langchain\\chat_models\\base.py:84\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     79\u001B[0m new_arg_supported \u001B[38;5;241m=\u001B[39m inspect\u001B[38;5;241m.\u001B[39msignature(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate)\u001B[38;5;241m.\u001B[39mparameters\u001B[38;5;241m.\u001B[39mget(\n\u001B[0;32m     80\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_manager\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     81\u001B[0m )\n\u001B[0;32m     82\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     83\u001B[0m     results \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m---> 84\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_generate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     85\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m new_arg_supported\n\u001B[0;32m     86\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate(m, stop\u001B[38;5;241m=\u001B[39mstop)\n\u001B[0;32m     87\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m m \u001B[38;5;129;01min\u001B[39;00m messages\n\u001B[0;32m     88\u001B[0m     ]\n\u001B[0;32m     89\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m, \u001B[38;5;167;01mException\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     90\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_llm_error(e)\n",
      "File \u001B[1;32mE:\\software\\Anaconda3\\envs\\myenv\\lib\\site-packages\\langchain\\chat_models\\openai.py:296\u001B[0m, in \u001B[0;36mChatOpenAI._generate\u001B[1;34m(self, messages, stop, run_manager)\u001B[0m\n\u001B[0;32m    292\u001B[0m     message \u001B[38;5;241m=\u001B[39m _convert_dict_to_message(\n\u001B[0;32m    293\u001B[0m         {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m\"\u001B[39m: inner_completion, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrole\u001B[39m\u001B[38;5;124m\"\u001B[39m: role}\n\u001B[0;32m    294\u001B[0m     )\n\u001B[0;32m    295\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ChatResult(generations\u001B[38;5;241m=\u001B[39m[ChatGeneration(message\u001B[38;5;241m=\u001B[39mmessage)])\n\u001B[1;32m--> 296\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompletion_with_retry(messages\u001B[38;5;241m=\u001B[39mmessage_dicts, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams)\n\u001B[0;32m    297\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_create_chat_result(response)\n",
      "File \u001B[1;32mE:\\software\\Anaconda3\\envs\\myenv\\lib\\site-packages\\langchain\\chat_models\\openai.py:257\u001B[0m, in \u001B[0;36mChatOpenAI.completion_with_retry\u001B[1;34m(self, **kwargs)\u001B[0m\n\u001B[0;32m    253\u001B[0m \u001B[38;5;129m@retry_decorator\u001B[39m\n\u001B[0;32m    254\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_completion_with_retry\u001B[39m(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[0;32m    255\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclient\u001B[38;5;241m.\u001B[39mcreate(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m--> 257\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _completion_with_retry(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mE:\\software\\Anaconda3\\envs\\myenv\\lib\\site-packages\\tenacity\\__init__.py:289\u001B[0m, in \u001B[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001B[1;34m(*args, **kw)\u001B[0m\n\u001B[0;32m    287\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(f)\n\u001B[0;32m    288\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped_f\u001B[39m(\u001B[38;5;241m*\u001B[39margs: t\u001B[38;5;241m.\u001B[39mAny, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw: t\u001B[38;5;241m.\u001B[39mAny) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m t\u001B[38;5;241m.\u001B[39mAny:\n\u001B[1;32m--> 289\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m(f, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw)\n",
      "File \u001B[1;32mE:\\software\\Anaconda3\\envs\\myenv\\lib\\site-packages\\tenacity\\__init__.py:389\u001B[0m, in \u001B[0;36mRetrying.__call__\u001B[1;34m(self, fn, *args, **kwargs)\u001B[0m\n\u001B[0;32m    387\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(do, DoSleep):\n\u001B[0;32m    388\u001B[0m     retry_state\u001B[38;5;241m.\u001B[39mprepare_for_next_attempt()\n\u001B[1;32m--> 389\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    390\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    391\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m do\n",
      "File \u001B[1;32mE:\\software\\Anaconda3\\envs\\myenv\\lib\\site-packages\\tenacity\\nap.py:31\u001B[0m, in \u001B[0;36msleep\u001B[1;34m(seconds)\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msleep\u001B[39m(seconds: \u001B[38;5;28mfloat\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     26\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     27\u001B[0m \u001B[38;5;124;03m    Sleep strategy that delays execution for a given number of seconds.\u001B[39;00m\n\u001B[0;32m     28\u001B[0m \n\u001B[0;32m     29\u001B[0m \u001B[38;5;124;03m    This is the default strategy, and may be mocked out for unit testing.\u001B[39;00m\n\u001B[0;32m     30\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 31\u001B[0m     \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mseconds\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import re\n",
    "import json\n",
    "\n",
    "abstract=[]\n",
    "result = []\n",
    "unprocess_list = []\n",
    "\n",
    "for text in inner:\n",
    "    try:\n",
    "        os.environ[\"OPENAI_API_KEY\"] = key_pool[random.randint(0,len(key_pool)-1)]\n",
    "        print(os.environ.get(\"OPENAI_API_KEY\"))\n",
    "        response=chain.run(text = text)\n",
    "        print(response)\n",
    "        res = chain2.run(text=text,abstract=response,respond_struction=format_instructions)\n",
    "        unprocess_list.append(out_parse.parse(res))\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "第三条链:用来去重,去掉每一次切割部分重叠的内容"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(len(unprocess_list)-1):\n",
    "    data1 = unprocess_list[i]['result']\n",
    "    data2 = unprocess_list[i+1]['result']\n",
    "    need_process_data = []\n",
    "    need_process_data.append(data1[len(data1)-1])\n",
    "    need_process_data.append(data2[0])\n",
    "    os.environ[\"OPENAI_API_KEY\"] = key_pool[random.randint(0,len(key_pool)-1)]\n",
    "    respone = chain3.run(text1=need_process_data[0],text2=need_process_data[1],respond_struction=format_instructions)\n",
    "    print(respone)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
