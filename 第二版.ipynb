{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "标题: 使用 # 来表示不同级别的标题，比如：\n",
    "\n",
    "# 一级标题\n",
    "## 二级标题\n",
    "### 三级标题\n",
    "粗体: 使用 ** 或 __ 来包围文本，例如：\n",
    "\n",
    "**这是粗体文本** 或 __这是粗体文本__\n",
    "斜体: 使用 * 或 _ 来包围文本，例如：\n",
    "\n",
    "*这是斜体文本* 或 _这是斜体文本_\n",
    "删除线: 使用 ~~ 来包围文本，例如：\n",
    "\n",
    "~~这是带有删除线的文本~~\n",
    "链接: 使用 []() 来创建一个链接，例如：\n",
    "\n",
    "[百度](http://www.baidu.com)\n",
    "图片: 使用 ![]() 来插入一个图片，例如：\n",
    "\n",
    "![图片描述](图片链接)\n",
    "无序列表: 使用 * 或 - 或 + 后接空格来创建无序列表，例如：\n",
    "\n",
    "* 项目1\n",
    "- 项目2\n",
    "+ 项目3\n",
    "有序列表: 使用数字和点后接空格来创建有序列表，例如：\n",
    "\n",
    "1. 项目1\n",
    "2. 项目2\n",
    "3. 项目3\n",
    "引用: 使用 > 来创建引用，例如：\n",
    "\n",
    "> 这是一段引用\n",
    "代码: 使用 ` ` 来插入内联代码，例如 这是一段代码。使用 ``` ``` 来插入代码块，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HTTP_PROXY'] = \"127.0.0.1:10809\"\n",
    "os.environ['HTTPS_PROXY']=\"127.0.0.1:10809\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 从key文件读取key值\n",
    "* 输入参数: file_path 文件路径\n",
    "* 返回值: 存有key的列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_keys_from_file(file_path):\n",
    "    key_pool = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            key = line.strip()  # 去掉每一行的换行符\n",
    "            key_pool.append(key)  # 将每一行存入key池中\n",
    "    return key_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 读取key\n",
    "file_path = \"key.txt\"  # 将这个替换为你的txt文件的路径\n",
    "key_pool = read_keys_from_file(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 读取PDF文档函数\n",
    "* 参数:文件路径file_path,提取前n页\n",
    "* 返回值:一个列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "\n",
    "def read_pdf(file_path, n):\n",
    "    inner = []\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "            # 提取前n页\n",
    "            for i, page in enumerate(pdf.pages):\n",
    "                # 如果已经处理了n页，就停止\n",
    "                if i == n:\n",
    "                    break\n",
    "                inner.append(page.extract_text())\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 按页数进行划分\n",
    "* 参数:inner->一个装有每一页pdf的列表\n",
    "* 参数:group_size->每个组的大小\n",
    "* 返回值:一个列表\n",
    "\n",
    "> 分割逻辑:\n",
    "> 以 inner = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 举例\n",
    "第一次循环：i = 0，子列表为 inner[0:0+4] = [1, 2, 3, 4]\n",
    "第二次循环：i = 3，子列表为 inner[3:3+4] = [4, 5, 6, 7]\n",
    "第三次循环：i = 6，子列表为 inner[6:6+4] = [7, 8, 9, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def group_inner(inner, group_size):\n",
    "    # 将inner按照每n页为一组进行分割\n",
    "    \"\"\"\n",
    "\n",
    "    :param inner:\n",
    "    :param group_size:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    grouped_inner = [inner[i:min(i + group_size, len(inner))] for i in range(0, len(inner), group_size - 1)]\n",
    "    return grouped_inner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "content = read_pdf(r'./data/KT820说明书V2.0 201909.pdf', 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inner = group_inner(content, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import  ChatPromptTemplate\n",
    "prompts = \"\"\"\n",
    "    ----\n",
    "    {text}\n",
    "    ----\n",
    "    帮我把上面内容总结成2-4个目录，不能超过4个,目录不要子目录，目录为简洁摘要，其它内容不用给我\n",
    "    \"\"\"\n",
    "\n",
    "prompts2 = \"\"\"\n",
    "    abstract:\n",
    "    ----\n",
    "    {abstract}\n",
    "    ----\n",
    "    text:\n",
    "    ----\n",
    "    {text}\n",
    "    ----\n",
    "\n",
    "    跟据上面的摘要，找出下面内容中每个摘要对应的开始位置内容,如果涉及到目录部分,有一大串的...就只返回三个就行,不用返回全部.：\n",
    "    返回格式:\n",
    "    [{respond_struction}]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompts3 = \"\"\"\n",
    "    text1:\n",
    "    ----\n",
    "    {text1}\n",
    "    ----\n",
    "    text2:\n",
    "    ----\n",
    "    {text2}\n",
    "    ----\n",
    "\n",
    "        现在，你有两个字典格式的文本字符串，它们分别命名为 text1 和 text2。这两个字典中都有一个content字段，你需要判断这两个字段中的内容是否相似。\n",
    "        如果它们的content相似，那么你需要合并这两个文本中的content字段的内容，并基于这个新的content生成一个新的abstract。返回的数据格式应该为一个字典，如下所示：\n",
    "        返回格式:\n",
    "        [{respond_struction}]\n",
    "        如果它们的content不相似，那么直接返回原来的两个字典格式的字符串文本 text1 和 text2。\n",
    "\n",
    "\"\"\"\n",
    "promptsTemplate = ChatPromptTemplate.from_template(prompts)\n",
    "promptsTemplate2 = ChatPromptTemplate.from_template(prompts2)\n",
    "promptsTemplate3 = ChatPromptTemplate.from_template(prompts3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 指定返回值格式\n",
    "> 返回值格式采用json数据,包含三部分:关键词,开始词,结束词\n",
    "### langchain的json格式\n",
    "1. 先定义单个模式,Schema = ResponseSchema(name=\"\",description=\"\")\n",
    "2. 然后将多个模式组合在一起response_schemas = [abstract_schema, start_schema, end_schema]\n",
    "3. 通过结构输出解析函数解析成结构对象 = StructuredOutputParser(response_schemas = response_schemas)\n",
    "4. 最后将结构对象解析成json格式的内容\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "result_schema = ResponseSchema(name='result', description=\"这一部分是一个数组,用来记录返回的内容的,里面的每一项都是一个字典,每个字典里面有两个key,一个key名为abstract。其对应的内容是摘要部分的内容, 也就是用来记录摘要的。另一个key的名字是content,这一部分是返回和上面摘要部分相关的全部内容,有n个摘要就返回n个内容\")\n",
    "# abstract_schema = ResponseSchema(name=\"abstract\",description=\"这是摘要部分的内容, 也就是用来记录摘要的\")\n",
    "# content_schema = ResponseSchema(name=\"content\",description=\"返回和上面摘要部分相关的全部内容,有n个摘要就返回n个内容\")\n",
    "\n",
    "response_schemas = [result_schema]\n",
    "out_parse = StructuredOutputParser(response_schemas = response_schemas)\n",
    "format_instructions = out_parse.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 制作两条链来定位\n",
    "* 第一条链用来摘要总结文本内容,第一条链用3.5的模型\n",
    "* 第二条链用来根据摘要来定位文本内容,第二条链用3.5模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import random\n",
    "# import re\n",
    "# import json\n",
    "# from langchain.chains import LLMChain\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "#\n",
    "# abstract=[]\n",
    "# result = []\n",
    "# unprocess_list = []\n",
    "# error_key = []\n",
    "#\n",
    "# for text in inner:\n",
    "#     try:\n",
    "#         os.environ[\"OPENAI_API_KEY\"] = key_pool[random.randint(0,len(key_pool)-1)]\n",
    "#         print(os.environ.get(\"OPENAI_API_KEY\"))\n",
    "#         llm = ChatOpenAI(model_name='gpt-3.5-turbo-16k', temperature=0)\n",
    "#         chain = LLMChain(llm=llm, prompt=promptsTemplate)\n",
    "#         chain2 = LLMChain(llm=llm, prompt=promptsTemplate2)\n",
    "#         response=chain.run(text = text)\n",
    "#         res = chain2.run(text=text,abstract=response,respond_struction=format_instructions)\n",
    "#         print(res)\n",
    "#         unprocess_list.append(out_parse.parse(res))\n",
    "#     except Exception as e:\n",
    "#         error_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "#         # 移除原来文本中对应的key\n",
    "#         key_pool.remove(error_key)\n",
    "#         with open('key.txt', 'w') as f:\n",
    "#             for key in key_pool:\n",
    "#                 f.write(key+'\\n')\n",
    "#\n",
    "#         with open('error_key.txt', 'a') as f:\n",
    "#             f.write(error_key + '\\n')\n",
    "#         print(\"An error occurred:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import concurrent.futures\n",
    "import time\n",
    "unprocess_list = [None] * len(inner)\n",
    "print(len(unprocess_list))\n",
    "\n",
    "# 处理文本函数\n",
    "def process_text(index, text):\n",
    "    time.sleep(random.uniform(10,30))  # 添加随机时间\n",
    "    try:\n",
    "        os.environ[\"OPENAI_API_KEY\"] = key_pool[index%(len(key_pool) - 1)]\n",
    "        print(\"调用chain1的key\",os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "        llm = ChatOpenAI(model_name='gpt-3.5-turbo-16k', temperature=0)\n",
    "        chain = LLMChain(llm=llm, prompt=promptsTemplate)\n",
    "        response = chain.run(text = text)\n",
    "        print(\"目录:\",response)\n",
    "        time.sleep(5)\n",
    "        time.sleep(random.uniform(1*index, 3*index))  #添加随机时间\n",
    "\n",
    "        os.environ[\"OPENAI_API_KEY\"] = key_pool[index%(len(key_pool) - 1)]\n",
    "        llm = ChatOpenAI(model_name='gpt-3.5-turbo-16k', temperature=0)\n",
    "        chain2 = LLMChain(llm=llm, prompt=promptsTemplate2)\n",
    "        print(\"调用chain2的key\",os.environ.get(\"OPENAI_API_KEY\"))\n",
    "        res = chain2.run(text=text, abstract=response, respond_struction=format_instructions)\n",
    "        print(res)\n",
    "        return index, out_parse.parse(res)\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "        return index, None\n",
    "\n",
    "# 创建一个ThreadPoolExecutor线程池\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    # 用于提交任务到线程池并获取结果的Future对象\n",
    "    futures = [executor.submit(process_text, index, text) for index, text in enumerate(inner)]\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        index, result = future.result()\n",
    "        if result is not None:\n",
    "            # 结果是按照顺序放入unprocess_list\n",
    "            unprocess_list[index] = result\n",
    "\n",
    "# 收集为unprocess_list为none的下标\n",
    "none_index = []\n",
    "for i, item in enumerate(unprocess_list):\n",
    "    if item is None:\n",
    "        none_index.append(i)\n",
    "print(none_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(unprocess_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 第三条链\n",
    "用来去重,去掉每一次切割部分重叠的内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(unprocess_list)-1):\n",
    "    data1 = unprocess_list[i]['result']\n",
    "    data2 = unprocess_list[i+1]['result']\n",
    "    need_process_data = []\n",
    "    need_process_data.append(data1[len(data1)-1])\n",
    "    need_process_data.append(data2[0])\n",
    "    os.environ[\"OPENAI_API_KEY\"] = key_pool[random.randint(0,len(key_pool)-1)]\n",
    "    llm = ChatOpenAI(model_name='gpt-3.5-turbo-16k', temperature=0, request_timeout=75000)\n",
    "    chain3 = LLMChain(llm=llm, prompt=promptsTemplate3)\n",
    "    respone = chain3.run(text1=need_process_data[0],text2=need_process_data[1],respond_struction=format_instructions)\n",
    "    # 解析返回文本\n",
    "    content = out_parse.parse(respone)\n",
    "    print(respone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
